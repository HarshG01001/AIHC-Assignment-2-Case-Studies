{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1Qhzh+ziVEnflaVRO68lN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshG01001/AIHC-Assignment-2-Case-Studies/blob/main/CaseStudy4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UifiLvBaAKbY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, IsolationForest\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset directly by its name\n",
        "file_name = 'hospital_readmissions.csv'\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "print(f\"'{file_name}' loaded successfully. Shape: {df.shape}\")\n",
        "\n",
        "# Replace '?' with NaN to correctly identify and count missing values\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "print(\"\\n--- Missing Values Check ---\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDOMWEQPAeIe",
        "outputId": "1efe1411-22e0-4fe6-be25-2dc1f52f1e57"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'hospital_readmissions.csv' loaded successfully. Shape: (25000, 17)\n",
            "\n",
            "--- Missing Values Check ---\n",
            "age                  0\n",
            "time_in_hospital     0\n",
            "n_lab_procedures     0\n",
            "n_procedures         0\n",
            "n_medications        0\n",
            "n_outpatient         0\n",
            "n_inpatient          0\n",
            "n_emergency          0\n",
            "medical_specialty    0\n",
            "diag_1               0\n",
            "diag_2               0\n",
            "diag_3               0\n",
            "glucose_test         0\n",
            "A1Ctest              0\n",
            "change               0\n",
            "diabetes_med         0\n",
            "readmitted           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Target Variable Engineering ---\n",
        "# Predict if a patient was readmitted in <30 days (binary target)\n",
        "df['readmitted_binary'] = (df['readmitted'] == 'yes').astype(int)\n",
        "\n",
        "# Check unique values in original 'readmitted' column\n",
        "print(\"\\n--- Unique values in 'readmitted' column ---\")\n",
        "print(df['readmitted'].unique())\n",
        "\n",
        "# --- Feature Selection ---\n",
        "# Drop identifiers and columns with many missing values\n",
        "cols_to_drop = ['medical_specialty', 'readmitted']\n",
        "df_clean = df.drop(columns=cols_to_drop)\n",
        "\n",
        "# --- Impute Missing Values ---\n",
        "# Drop rows with missing values in key categorical columns\n",
        "df_clean.dropna(subset=['diag_1', 'diag_2', 'diag_3'], inplace=True)\n",
        "\n",
        "# --- Identify Feature Types ---\n",
        "numerical_features = df_clean.select_dtypes(include=np.number).columns.drop('readmitted_binary').tolist()\n",
        "categorical_features = df_clean.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "# --- Create Preprocessing Pipeline ---\n",
        "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "print(\"Preprocessing pipeline created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPpWv4KSArIY",
        "outputId": "d9d9add3-38b9-4e83-ba2e-a2269a7690af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Unique values in 'readmitted' column ---\n",
            "['no' 'yes']\n",
            "Preprocessing pipeline created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target (y) for classification\n",
        "X = df_clean.drop('readmitted_binary', axis=1)\n",
        "y = df_clean['readmitted_binary']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Check the class distribution in the training and testing sets\n",
        "print(\"\\n--- Class Distribution in y_train ---\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(\"\\n--- Class Distribution in y_test ---\")\n",
        "print(y_test.value_counts())\n",
        "\n",
        "\n",
        "# Define models\n",
        "classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, classifier in classifiers.items():\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', classifier)])\n",
        "\n",
        "    print(f\"--- Training {name} ---\")\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    print(f\"\\n--- {name} Evaluation ---\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Not Readmitted', 'Readmitted <30']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyGgfVJaA6Gr",
        "outputId": "6009d5ac-3eda-44cc-d053-166d4e518d90"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Class Distribution in y_train ---\n",
            "readmitted_binary\n",
            "0    10597\n",
            "1     9403\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Class Distribution in y_test ---\n",
            "readmitted_binary\n",
            "0    2649\n",
            "1    2351\n",
            "Name: count, dtype: int64\n",
            "--- Training Logistic Regression ---\n",
            "\n",
            "--- Logistic Regression Evaluation ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Readmitted       0.60      0.79      0.68      2649\n",
            "Readmitted <30       0.64      0.41      0.50      2351\n",
            "\n",
            "      accuracy                           0.61      5000\n",
            "     macro avg       0.62      0.60      0.59      5000\n",
            "  weighted avg       0.62      0.61      0.60      5000\n",
            "\n",
            "--- Training Random Forest ---\n",
            "\n",
            "--- Random Forest Evaluation ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Readmitted       0.60      0.67      0.63      2649\n",
            "Readmitted <30       0.57      0.50      0.53      2351\n",
            "\n",
            "      accuracy                           0.59      5000\n",
            "     macro avg       0.59      0.59      0.58      5000\n",
            "  weighted avg       0.59      0.59      0.59      5000\n",
            "\n",
            "--- Training Gradient Boosting ---\n",
            "\n",
            "--- Gradient Boosting Evaluation ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Readmitted       0.62      0.75      0.68      2649\n",
            "Readmitted <30       0.63      0.47      0.54      2351\n",
            "\n",
            "      accuracy                           0.62      5000\n",
            "     macro avg       0.62      0.61      0.61      5000\n",
            "  weighted avg       0.62      0.62      0.61      5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target (y) for regression\n",
        "y_reg = X['time_in_hospital']\n",
        "X_reg = X.drop('time_in_hospital', axis=1)\n",
        "\n",
        "# Update the preprocessor to exclude the new target from the feature set\n",
        "numerical_features_reg = [col for col in numerical_features if col != 'time_in_hospital']\n",
        "preprocessor_reg = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_features_reg),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split data\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Linear Regression pipeline\n",
        "lin_reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor_reg),\n",
        "                                   ('regressor', LinearRegression())])\n",
        "\n",
        "print(\"--- Training Linear Regression ---\")\n",
        "lin_reg_pipeline.fit(X_train_reg, y_train_reg)\n",
        "y_pred_reg = lin_reg_pipeline.predict(X_test_reg)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
        "\n",
        "print(\"\\n--- Linear Regression Evaluation ---\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNpyGF2_CK2a",
        "outputId": "17cf8590-e8e7-4be4-9a2d-11c28c84375c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Linear Regression ---\n",
            "\n",
            "--- Linear Regression Evaluation ---\n",
            "Mean Absolute Error (MAE): 1.9378\n",
            "Root Mean Squared Error (RMSE): 2.5370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocessor to the training data\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Apply Isolation Forest\n",
        "# Contamination is the expected proportion of anomalies (e.g., 5%)\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "train_anomalies = iso_forest.fit_predict(X_train_processed) # -1 for anomalies, 1 for inliers\n",
        "\n",
        "# Add anomaly flags back to the original training dataframe\n",
        "X_train['anomaly'] = train_anomalies\n",
        "\n",
        "# Analyze the results\n",
        "print(\"--- Isolation Forest Anomaly Detection ---\")\n",
        "print(f\"Number of anomalies detected in the training set: {(X_train['anomaly'] == -1).sum()}\")\n",
        "\n",
        "# Check if the detected anomalies have a higher readmission rate\n",
        "anomaly_readmission_rate = y_train[X_train['anomaly'] == -1].mean()\n",
        "normal_readmission_rate = y_train[X_train['anomaly'] == 1].mean()\n",
        "\n",
        "print(f\"\\nReadmission rate for detected anomalies: {anomaly_readmission_rate:.2%}\")\n",
        "print(f\"Readmission rate for normal records: {normal_readmission_rate:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55eaES9VCO-3",
        "outputId": "e9b0817c-f3cf-438c-a434-23d6ccd20b50"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Isolation Forest Anomaly Detection ---\n",
            "Number of anomalies detected in the training set: 1000\n",
            "\n",
            "Readmission rate for detected anomalies: 52.60%\n",
            "Readmission rate for normal records: 46.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocessor to the training data\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Apply Isolation Forest\n",
        "# Contamination is the expected proportion of anomalies (e.g., 5%)\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "train_anomalies = iso_forest.fit_predict(X_train_processed) # -1 for anomalies, 1 for inliers\n",
        "\n",
        "# Add anomaly flags back to the original training dataframe\n",
        "X_train['anomaly'] = train_anomalies\n",
        "\n",
        "# Analyze the results\n",
        "print(\"--- Isolation Forest Anomaly Detection ---\")\n",
        "print(f\"Number of anomalies detected in the training set: {(X_train['anomaly'] == -1).sum()}\")\n",
        "\n",
        "# Check if the detected anomalies have a higher readmission rate\n",
        "anomaly_readmission_rate = y_train[X_train['anomaly'] == -1].mean()\n",
        "normal_readmission_rate = y_train[X_train['anomaly'] == 1].mean()\n",
        "\n",
        "print(f\"\\nReadmission rate for detected anomalies: {anomaly_readmission_rate:.2%}\")\n",
        "print(f\"Readmission rate for normal records: {normal_readmission_rate:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yGSiTBoCSBo",
        "outputId": "318742ac-d487-4f14-b7f4-14ce430e89de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Isolation Forest Anomaly Detection ---\n",
            "Number of anomalies detected in the training set: 1000\n",
            "\n",
            "Readmission rate for detected anomalies: 52.60%\n",
            "Readmission rate for normal records: 46.72%\n"
          ]
        }
      ]
    }
  ]
}